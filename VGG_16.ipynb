{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f432358b-7d18-4da1-95a1-93c7eb7502bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import time\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from torchviz import make_dot\n",
    "import random\n",
    "\n",
    "from dataclasses import make_dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31b43e8-f714-4a17-8cb3-f81b3771db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd63e1b2-5f66-4122-83f4-75502878f879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 12500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "TRAIN_DIR = './train/train'\n",
    "TEST_DIR = './test1/test1'\n",
    "\n",
    "train_list = glob.glob(os.path.join(TRAIN_DIR,'*.jpg'))\n",
    "test_list = glob.glob(os.path.join(TEST_DIR, '*.jpg'))\n",
    "\n",
    "len(train_list), len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf323770-6f26-4fa3-8749-2e497a049a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.backends.cudnn.benchmark , torch.backends.cudnn.deterministic)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bbd59a-3dc2-42cc-a332-773702159c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trlist, valist = train_test_split(train_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd571a6e-0823-4820-87fe-33834bae1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=40, translate=None, scale=(1, 2), shear=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.ToTensor(), \n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419ab00e-cfcd-4aed-9058-68d28f06c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img_aug = self.transform(img)\n",
    "            \n",
    "        label = img_path.split('\\\\')[-1].split('.')[0]\n",
    "        if label == 'dog':\n",
    "            label = 1\n",
    "        elif label == 'cat':\n",
    "            label = 0\n",
    "        \n",
    "        return img_aug, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034dd1de-3ed9-4ded-9abd-914e1609683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trlist, valist = train_test_split(train_list, test_size=0.25)\n",
    "\n",
    "training_dataset= dataset(trlist, transform=data_transforms['train'])\n",
    "validation_dataset = dataset(valist, transform=data_transforms['test'])\n",
    "testing_dataset = dataset(test_list, transform=data_transforms['test'])\n",
    "\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory = True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af66343-d010-412a-8147-9148e9275ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750\n",
      "6250\n"
     ]
    }
   ],
   "source": [
    "print(len(training_dataloader.dataset))\n",
    "print(len(validation_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec354052-4783-4d3e-a98b-2201b072a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16( weights='DEFAULT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63122d0e-e810-4696-947a-ded942d292c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features, 2)]) # Add our layer with 4 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c383dab-252d-4f1f-8a66-07baa513d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775ca50c-94d3-4f7e-b733-a20a13848872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epoch):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "    net = net.to(device)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "        print('-'*20)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "                \n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloader_dict):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloader_dict.dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict.dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99bc6511-40ac-422f-8bf3-e49da1cfb4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [12:37<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1414 Acc: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0757 Acc: 0.9701\n",
      "Epoch 2/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0784 Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0608 Acc: 0.9750\n",
      "Epoch 3/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0705 Acc: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0560 Acc: 0.9774\n",
      "Epoch 4/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0646 Acc: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0501 Acc: 0.9804\n",
      "Epoch 5/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0563 Acc: 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0472 Acc: 0.9812\n",
      "Epoch 6/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0537 Acc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:33<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0472 Acc: 0.9825\n",
      "Epoch 7/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0476 Acc: 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0414 Acc: 0.9842\n",
      "Epoch 8/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0475 Acc: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0390 Acc: 0.9848\n",
      "Epoch 9/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0433 Acc: 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0390 Acc: 0.9847\n",
      "Epoch 10/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [13:46<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0437 Acc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:34<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0388 Acc: 0.9855\n",
      "Training complete in 172m 19s\n",
      "Best val Acc: 0.985493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vgg16 = train_model(vgg16 , training_dataloader , criterion , optimizer ,  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1542893-3522-4a23-be8c-3ea09d7edcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), './vgg16transferLearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57914dfb-3353-4482-9f03-50143b0f7347",
   "metadata": {},
   "source": [
    "VGG 16 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce11fedd-90cd-4f47-8d15-2e5cc7bba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predicted_labels.extend(predicted.cpu().numpy())  # Convert predictions to numpy array\n",
    "            true_labels.extend(labels.cpu().numpy())  # Convert true labels to numpy array\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8dbdc13-04f1-4203-b780-a7e8aac9cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.70%\n",
      "Precision: 0.95\n",
      "Recall: 0.95\n",
      "F1-score: 0.95\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = evaluate_model(vgg16, validation_dataloader, device)\n",
    "print('Accuracy: %.2f%%' % accuracy)\n",
    "print('Precision: %.2f' % precision)\n",
    "print('Recall: %.2f' % recall)\n",
    "print('F1-score: %.2f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88fe74-6692-4a0c-a58b-f55892b93d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
